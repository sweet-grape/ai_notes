<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ComfyUI 学习教程</title>
  <meta name="description" content="从零上手 ComfyUI 的完整学习教程与实战工作流" />
  <link rel="stylesheet" href="./style.css" />
</head>
<body>
  <header class="site-header">
    <div class="container header-inner">
      <a class="brand" href="./index.html">ComfyUI 学习站</a>
      <nav class="nav" id="topNav">
        <a href="./index.html" class="nav-link">首页</a>
        <a href="./tutorial.html" class="nav-link active">学习教程</a>
        <a href="./cases.html" class="nav-link">案例展示</a>
        <a href="https://github.com/comfyanonymous/ComfyUI" class="nav-link" target="_blank" rel="noopener">GitHub</a>
      </nav>
      <button class="nav-toggle" id="navToggle" aria-label="切换导航">☰</button>
    </div>
  </header>

  <main class="container with-sidebar">
    <aside class="sidebar">
      <div class="toc">
        <div class="toc-title">目录</div>
        <a href="#intro">1. 认识 ComfyUI</a>
        <a href="#install" id="install">2. 安装与启动</a>
        <a href="#ui">3. 界面与节点基础</a>
        <a href="#workflows" id="workflows">4. 核心工作流实战</a>
        <a href="#models">5. 模型管理与放置路径</a>
        <a href="#optimize">6. 性能优化建议</a>
        <a href="#export">7. 工作流的保存与分享</a>
        <a href="#troubleshooting" id="troubleshooting">8. 常见问题排查</a>
        <a href="#online-cn" id="online-cn-link">9. 在线部署与体验（中国境内）</a>
      </div>
    </aside>

    <article class="doc">
      <h1>ComfyUI 学习教程</h1>
      <p class="lead">本教程面向初学者与进阶用户，覆盖安装配置、界面与节点基础、文生图/图生图/ControlNet/LoRA 等核心工作流，以及性能优化与常见问题排查。</p>

      <h2 id="intro">1. 认识 ComfyUI</h2>
      <p>ComfyUI 是一个<strong>节点式</strong>的可视化 AI 工作流工具。与传统一键式 UI 不同，ComfyUI 通过将推理流程拆解为节点并以连线的方式组合，带来高度的灵活性与可复用性。</p>
      <ul>
        <li><strong>可视化流程</strong>：所见即所得，方便调试与复用。</li>
        <li><strong>高度可扩展</strong>：支持自定义节点与各类插件。</li>
        <li><strong>精细控制</strong>：对采样、引导、VAE、LoRA、ControlNet 等细节可逐一调参。</li>
      </ul>

      <h2 id="install">2. 安装与启动</h2>
      <h3>2.1 环境准备</h3>
      <ul>
        <li>操作系统：Windows 10/11（推荐）、Linux、macOS</li>
        <li>Python：3.10 或 3.11</li>
        <li>Git：用于拉取仓库与更新</li>
        <li>GPU（推荐）：NVIDIA 显卡 + 合适的 CUDA 驱动</li>
      </ul>
      <h4>2.1.1 电脑配置推荐（保证良好体验）</h4>
      <div class="cards" style="margin-top:12px">
        <article class="card">
          <h3>入门可用（1080p 起步）</h3>
          <ul>
            <li>GPU：RTX 3060 12GB 或 RTX 4060 8GB</li>
            <li>CPU：6 核以上（Intel i5-12400/AMD 5600 及以上）</li>
            <li>内存：16GB</li>
            <li>硬盘：NVMe SSD ≥ 1TB（模型/缓存更快）</li>
            <li>适用：768～1024 分辨率，基础文生图/图生图</li>
          </ul>
        </article>
        <article class="card">
          <h3>甜点畅玩（更流畅）</h3>
          <ul>
            <li>GPU：RTX 4070 12GB 或 RTX 4070 Super</li>
            <li>CPU：8 核以上（Intel i7-12700/AMD 7700 及以上）</li>
            <li>内存：32GB</li>
            <li>硬盘：NVMe SSD 1–2TB</li>
            <li>适用：1024～1536 分辨率，ControlNet/LoRA 多组合</li>
          </ul>
        </article>
        <article class="card">
          <h3>高阶创作（大图/多模型）</h3>
          <ul>
            <li>GPU：RTX 4080(S) 16GB 或 RTX 4090 24GB</li>
            <li>CPU：高频 8–16 核（Intel i7/i9 13 代或 Ryzen 7/9 新款）</li>
            <li>内存：64GB（多任务/大型工作流更稳）</li>
            <li>硬盘：NVMe SSD 2TB+（建议独立“模型盘”）</li>
            <li>适用：2K 以上分辨率、放大精修、批量生成与视频插件</li>
          </ul>
        </article>
      </div>
      <p class="notice">显存是影响体验的关键：<strong>≥12GB</strong> 可较为从容地运行 1024 分辨率和常用 ControlNet；若显存吃紧，可降低分辨率/批量或改用放大流程。</p>
      <p class="notice">移动端建议优先选配带独显（如 4070/4080）的游戏本，并确保电源模式为性能优先；Apple Silicon 可通过 WebUI/Apple ML 方案体验基础功能（速度较慢）。</p>
      <h3>2.2 获取代码与依赖</h3>
      <pre class="code"><code>git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
python -m venv venv
venv\Scripts\activate   # Windows；Linux/macOS 使用: source venv/bin/activate
pip install --upgrade pip
# 按你的 CUDA 版本安装 PyTorch（以下示例为 CUDA 12.1）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt</code></pre>
      <p>若无独显或仅测试环境，可安装 CPU 版 PyTorch（速度较慢）：</p>
      <pre class="code"><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu</code></pre>

      <h3>2.3 启动服务</h3>
      <pre class="code"><code>python main.py --listen 0.0.0.0 --port 8188</code></pre>
      <p>浏览器访问 <code>http://127.0.0.1:8188/</code>（或你的服务器 IP）。</p>

      <h3 id="online">2.4 在线体验（中国境内）</h3>
      <div class="cards">
        <article class="card">
          <h3>方案 A：国内云 GPU（推荐）</h3>
          <ul>
            <li>平台：阿里云、腾讯云、华为云、火山引擎等，优先选择 ≥12–24GB 显存规格。</li>
            <li>系统：Ubuntu 22.04 + NVIDIA 驱动 + 匹配 CUDA。</li>
            <li>部署（示例）：</li>
          </ul>
          <pre class="code"><code>sudo apt update && sudo apt install -y git python3-venv
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
python3 -m venv venv && source venv/bin/activate
pip install --upgrade pip
# 按你的 CUDA 版本选择 PyTorch（示例 CUDA 12.1）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
python main.py --listen 0.0.0.0 --port 8188
# 在云厂商安全组/防火墙放行 80/443（反代）或 8188 端口</code></pre>
        </article>

        <article class="card">
          <h3>方案 B：Notebook / 容器平台</h3>
          <ul>
            <li>在支持 GPU 的国内平台创建 Notebook/容器实例。</li>
            <li>按上面命令拉取并运行，开启“端口映射/临时公网服务”。</li>
            <li>特点：计时计费、按需开关，适合教学演示与短期使用。</li>
          </ul>
        </article>

        <article class="card">
          <h3>方案 C：内网部署 + 远程访问</h3>
          <ul>
            <li>在办公室/家中独显主机上部署 ComfyUI。</li>
            <li>通过 FRP/ZeroTier/内网穿透或 Nginx 反向代理，以 HTTPS 暴露访问。</li>
            <li>务必启用访问控制与速率限制，保护模型与图片隐私。</li>
          </ul>
        </article>
      </div>
      <p class="notice">提示：公开在线服务需遵守版权与内容合规；为控制成本可设置“空闲自动关机/释放实例”；建议用域名 + HTTPS 代理至 8188 端口。</p>

      <h2 id="ui">3. 界面与节点基础</h2>
      <ul>
        <li><strong>画布（Canvas）</strong>：放置与连接节点的区域，支持拖拽与缩放。</li>
        <li><strong>节点搜索</strong>：双击画布或空格键，快速创建所需节点。</li>
        <li><strong>侧边栏</strong>：队列、历史记录、性能统计、系统日志等。</li>
        <li><strong>参数面板</strong>：选中节点后在右侧栏调参。</li>
      </ul>
      <p><strong>常用节点速览</strong>：</p>
      <ul>
        <li>模型相关：Load Checkpoint、VAE Encode/Decode、CLIP Text Encode</li>
        <li>采样相关：KSampler（选择采样器、步数、CFG 等）</li>
        <li>图像 I/O：Load Image、Save Image</li>
        <li>控制相关：Load ControlNet Model、Apply ControlNet</li>
      </ul>

      <h2 id="workflows">4. 核心工作流实战</h2>
      <h3>4.1 文生图（Text-to-Image）</h3>
      <ol>
        <li>添加 <em>Load Checkpoint</em>（选择主模型）</li>
        <li>添加 <em>CLIP Text Encode</em> 两个节点：Prompt 与 Negative Prompt</li>
        <li>添加 <em>Empty Latent Image</em>（设置分辨率，如 1024×1024）</li>
        <li>添加 <em>KSampler</em>（采样器、步数、CFG、种子）</li>
        <li>添加 <em>VAE Decode</em> 与 <em>Save Image</em></li>
      </ol>
      <p><strong>连接关系（简化）</strong>：</p>
      <pre class="code"><code>Load Checkpoint → KSampler（model、vae、clip）
CLIP Text Encode（正） → KSampler positive
CLIP Text Encode（负） → KSampler negative
Empty Latent Image → KSampler latent
KSampler → VAE Decode → Save Image</code></pre>

      <h3>4.2 图生图（Image-to-Image）</h3>
      <ol>
        <li><em>Load Image</em> → <em>VAE Encode</em> 获取 latent</li>
        <li>与 4.1 类似连接到 <em>KSampler</em>，但 latent 输入来自 <em>VAE Encode</em></li>
        <li>采样强度可通过步数、噪声、去噪强度等控制</li>
      </ol>

      <h3>4.3 ControlNet（结构/姿态/边缘约束）</h3>
      <ol>
        <li>添加 <em>Load ControlNet Model</em>（选择相应的 control 模型）</li>
        <li>添加预处理（如 Canny、OpenPose 等，部分需扩展节点）并输出提示图</li>
        <li><em>Apply ControlNet</em> 将控制条件接入 <em>KSampler</em></li>
      </ol>
      <p>建议从 Canny/Lineart 入手，权重从 0.8 降到 0.4 寻找平衡。</p>

      <h3>4.4 LoRA（风格/角色注入）</h3>
      <ol>
        <li>将 LoRA 模型放到 <code>models/loras</code></li>
        <li>使用 <em>CLIP Text Encode</em> 的提示词中添加 <code>&lt;lora:名称:权重&gt;</code></li>
        <li>或使用相应的 LoRA 注入节点（部分为扩展节点）</li>
      </ol>

      <h3>4.5 放大与精修（Upscale & Refine）</h3>
      <ul>
        <li>基础放大：<em>Upscale</em> 节点（选择算法：ESRGAN/BSRGAN/Nearest 等）</li>
        <li>高分修复：先放大后再进 <em>VAE Encode → KSampler → VAE Decode</em> 做细化</li>
        <li>面部修复：GFPGAN/CodeFormer（通常作为扩展节点）</li>
      </ul>

      <h2 id="models">5. 模型管理与放置路径</h2>
      <ul>
        <li>主模型（.safetensors/.ckpt）：<code>models/checkpoints</code></li>
        <li>VAE：<code>models/vae</code></li>
        <li>LoRA：<code>models/loras</code></li>
        <li>ControlNet：<code>models/controlnet</code></li>
        <li>嵌入/文本反演（Textual Inversion）：<code>embeddings</code></li>
      </ul>
      <p>放置完毕后在 UI 中点刷新（或重启）以识别新模型。</p>

      <h2 id="optimize">6. 性能优化建议</h2>
      <ul>
        <li>优先使用与显卡驱动匹配的 CUDA + PyTorch 版本</li>
        <li>分辨率从 768 或 1024 起步，逐步提升，结合放大流程</li>
        <li>采样步数常用 20–30，CFG 6–8 起步，按风格微调</li>
        <li>显存吃紧可降低 batch、分辨率，或启用 xformers/半精度</li>
        <li>固定随机种子以复现结果；探索时使用 -1 随机</li>
      </ul>

      <h2 id="export">7. 工作流的保存与分享</h2>
      <ul>
        <li>右上角导出/保存 <code>workflow.json</code></li>
        <li>他人可通过导入 JSON 快速复现你的流程</li>
        <li>截图画布并附上主要参数，有助于协作讨论</li>
      </ul>

      <h2 id="troubleshooting">8. 常见问题排查</h2>
      <details>
        <summary>8.1 启动后网页打不开</summary>
        <ul>
          <li>确认控制台无报错，端口 8188 未被占用</li>
          <li>尝试 <code>http://127.0.0.1:8188/</code> 或关闭代理软件</li>
          <li>服务器部署需放行防火墙端口或经反向代理暴露</li>
        </ul>
      </details>
      <details>
        <summary>8.2 无法识别 GPU / 加速无效</summary>
        <ul>
          <li>确认安装了 <strong>匹配 CUDA 版本</strong> 的 PyTorch（官网选择器）</li>
          <li>更新显卡驱动，检查 <code>nvidia-smi</code> 是否正常</li>
          <li>若仍失败，先用 CPU 版验证环境，再回退/更换 CUDA 版本</li>
        </ul>
      </details>
      <details>
        <summary>8.3 模型未显示或加载失败</summary>
        <ul>
          <li>确认放置在正确目录（见第 5 节）</li>
          <li>模型文件损坏可对比哈希或重新下载</li>
          <li>重启 ComfyUI 或点击 UI 刷新列表</li>
        </ul>
      </details>

      <h2 id="online-cn">9. 在线部署与体验（中国境内）</h2>
      <p class="lead">面向中国境内用户提供可落地的在线访问方案，包括国内云 GPU、Docker/Notebook 平台与内网部署穿透，以及安全加固与运维要点。</p>

      <h3>9.1 方案选择速览</h3>
      <div class="cards">
        <article class="card">
          <h3>国内云 GPU（推荐）</h3>
          <ul>
            <li>优点：弹性计费、带宽稳定、备案域名可用、维护省心</li>
            <li>建议：选择 ≥12–24GB 显存（如 L4/4090/A10/3090）</li>
            <li>适用：对外演示、团队协作、长期稳定服务</li>
          </ul>
        </article>
        <article class="card">
          <h3>Docker / Notebook 平台</h3>
          <ul>
            <li>优点：即开即用、镜像封装、便于教学与短期实验</li>
            <li>建议：开启端口映射或临时公网访问，挂载数据盘</li>
            <li>适用：课堂演示、临时项目、多人共享算力</li>
          </ul>
        </article>
        <article class="card">
          <h3>内网部署 + 穿透</h3>
          <ul>
            <li>优点：本地显卡零成本复用、可离线</li>
            <li>建议：使用 FRP/ZeroTier/反向代理并启用鉴权与限速</li>
            <li>适用：个人/小组内部访问，对公网稳定性要求不高</li>
          </ul>
        </article>
      </div>

      <h3>9.2 国内云 GPU 部署（生产推荐）</h3>
      <ol>
        <li><strong>创建实例</strong>：选择带 NVIDIA 显卡的镜像（或厂商提供的深度学习镜像）。显存 ≥12GB 为佳。</li>
        <li><strong>放行端口</strong>：安全组开放 22、80、443（用于反向代理与证书），可选开放 8188（直连）。</li>
        <li><strong>安装依赖并部署</strong>（Ubuntu 22.04 示例）：</li>
      </ol>
      <pre class="code"><code>sudo apt update && sudo apt install -y git python3-venv nginx apache2-utils
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
python3 -m venv venv && source venv/bin/activate
pip install --upgrade pip
# 按 CUDA 版本选择 PyTorch（示例 CUDA 12.1）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
nohup python main.py --listen 127.0.0.1 --port 8188 & disown
</code></pre>
      <p>说明：服务仅监听 127.0.0.1，由 Nginx 反代对外暴露，便于加密与鉴权。</p>

      <h4>为域名配置 Nginx 反向代理 + 基本认证</h4>
      <pre class="code"><code># 创建访问账户（可多次新增）
sudo htpasswd -c /etc/nginx/.htpasswd admin

sudo tee /etc/nginx/sites-available/comfyui &>/dev/null &lt;&lt;'CONF'
server {
  listen 80;
  server_name comfy.example.com;  # 改为你的域名

  location / {
    proxy_pass http://127.0.0.1:8188;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    auth_basic "Restricted";
    auth_basic_user_file /etc/nginx/.htpasswd;
    # 简单限速（可选）
    limit_req_zone $binary_remote_addr zone=one:10m rate=5r/s;
    limit_req zone=one burst=10 nodelay;
  }
}
CONF

sudo ln -s /etc/nginx/sites-available/comfyui /etc/nginx/sites-enabled/comfyui
sudo nginx -t && sudo systemctl reload nginx
</code></pre>
      <p class="notice">HTTPS：可用证书管理服务或 <code>acme.sh</code> 一键申请并将上面 server 块改为 443，强烈建议启用。</p>

      <h3>9.3 Docker / Notebook 快速方案</h3>
      <p>若平台提供 GPU Notebook/容器，可直接按下述命令启动（Ubuntu + NVIDIA Container Toolkit 示例）。</p>
      <pre class="code"><code># 安装 Docker 与 NVIDIA 容器支持
curl -fsSL https://get.docker.com | sudo sh
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt update && sudo apt install -y nvidia-container-toolkit && sudo systemctl restart docker

# 以 CUDA 运行时镜像启动容器并内部部署 ComfyUI（简化示例）
docker run --gpus all -d --name comfyui -p 8188:8188 \
  -v /data/comfyui:/workspace \
  nvidia/cuda:12.1.1-cudnn-runtime-ubuntu22.04 bash -lc '
    apt update && apt install -y git python3-venv && \
    cd /workspace && git clone https://github.com/comfyanonymous/ComfyUI.git && \
    cd ComfyUI && python3 -m venv venv && . venv/bin/activate && \
    pip install --upgrade pip && \
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 && \
    pip install -r requirements.txt && \
    python main.py --listen 0.0.0.0 --port 8188'
</code></pre>
      <p class="notice">如平台自带“临时公网/端口映射”，将 8188 映射出去即可；或同 9.2 用 Nginx 做 80/443 反代与鉴权。</p>

      <h3>9.4 内网部署 + 穿透（FRP 示例）</h3>
      <p>准备一台具有公网 IP 的轻量服务器部署 frps，本地显卡主机运行 frpc，将内网 8188 暴露为域名访问。</p>
      <pre class="code"><code># 在公网服务器安装 frps（以二进制包为例）
wget https://github.com/fatedier/frp/releases/download/v0.58.0/frp_0.58.0_linux_amd64.tar.gz
tar xf frp_0.58.0_linux_amd64.tar.gz && cd frp_0.58.0_linux_amd64
cat &gt; frps.ini &lt;&lt;EOF
[common]
bind_port = 7000
vhost_http_port = 80
vhost_https_port = 443
EOF
./frps -c frps.ini

# 本地显卡主机（Windows/Linux）创建 frpc.ini
[common]
server_addr = 公网服务器IP
server_port = 7000
[comfyui]
type = http
local_port = 8188
custom_domains = comfy.yourdomain.com

# 启动 frpc 后，用域名访问；可再配 Nginx/HTTPS 与基本认证
</code></pre>

      <h3>9.5 作为系统服务运行（systemd）</h3>
      <pre class="code"><code>sudo tee /etc/systemd/system/comfyui.service &>/dev/null &lt;&lt;'UNIT'
[Unit]
Description=ComfyUI Service
After=network.target

[Service]
WorkingDirectory=/opt/ComfyUI
ExecStart=/opt/ComfyUI/venv/bin/python main.py --listen 127.0.0.1 --port 8188
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
UNIT
sudo systemctl daemon-reload
sudo systemctl enable --now comfyui
</code></pre>

      <h3>9.6 安全与运维清单</h3>
      <ul>
        <li>避免直连 8188，对外统一走 Nginx 443，启用 HTTPS 与基本认证。</li>
        <li>限制上传与并发、开启限速；必要时加 WAF/防火墙白名单。</li>
        <li>模型与生成内容合规：注意版权、人物肖像与敏感内容过滤。</li>
        <li>成本控制：空闲自动关机/释放实例，定时同步模型至对象存储。</li>
        <li>监控：<code>nvidia-smi -l</code> 观察显存/功耗，日志保存在运行目录。</li>
      </ul>
    </article>
  </main>

  <footer class="site-footer">
    <div class="container">
      <span>© 2025 ComfyUI 学习站</span>
      <span class="sep">·</span>
      <a href="./index.html">首页</a>
      <span class="sep">·</span>
      <a href="./cases.html">案例展示</a>
    </div>
  </footer>

  <script src="./main.js"></script>
</body>
</html>



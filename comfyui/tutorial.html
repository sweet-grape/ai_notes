<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ComfyUI 学习教程</title>
  <meta name="description" content="从零上手 ComfyUI 的完整学习教程与实战工作流" />
  <link rel="stylesheet" href="./style.css" />
</head>
<body>
  <header class="site-header">
    <div class="container header-inner">
      <a class="brand" href="./index.html">ComfyUI 学习站</a>
      <nav class="nav" id="topNav">
        <a href="../../index.html#catalog" class="nav-link">返回首页目录</a>
        <a href="./index.html" class="nav-link">首页</a>
        <a href="./tutorial.html" class="nav-link active">学习教程</a>
        <a href="./cases.html" class="nav-link">案例展示</a>
        <a href="https://github.com/comfyanonymous/ComfyUI" class="nav-link" target="_blank" rel="noopener">GitHub</a>
      </nav>
      <button class="nav-toggle" id="navToggle" aria-label="切换导航">☰</button>
    </div>
  </header>

  <main class="container with-sidebar">
    <aside class="sidebar">
      <div class="toc">
        <div class="toc-title">目录</div>
        <a href="#intro">1. 认识 ComfyUI</a>
        <a href="#install" id="install">2. 安装与启动</a>
        <a href="#ui">3. 界面与节点基础</a>
        <a href="#workflows" id="workflows">4. 核心工作流实战</a>
        <a href="#models">5. 模型管理与放置路径</a>
        <a href="#optimize">6. 性能优化建议</a>
        <a href="#export">7. 工作流的保存与分享</a>
        <a href="#troubleshooting" id="troubleshooting">8. 常见问题排查</a>
        <a href="#online-cn" id="online-cn-link">9. 在线部署与体验（中国境内）</a>
        <a href="#runninghub" id="runninghub-link">RunningHub 云平台学习教程</a>
        <a href="#liblib" id="liblib-link">Liblib.art 云平台学习教程</a>
        <a href="#liblib-lora" id="liblib-lora-link">Liblib.art LoRA 训练教程</a>
      </div>
    </aside>

    <article class="doc">
      <h1>ComfyUI 学习教程</h1>
      <p class="lead">本教程面向初学者与进阶用户，覆盖安装配置、界面与节点基础、文生图/图生图/ControlNet/LoRA 等核心工作流，以及性能优化与常见问题排查。</p>

      <h2 id="intro">1. 认识 ComfyUI</h2>
      <p>ComfyUI 是一个<strong>节点式</strong>的可视化 AI 工作流工具。与传统一键式 UI 不同，ComfyUI 通过将推理流程拆解为节点并以连线的方式组合，带来高度的灵活性与可复用性。</p>
      <ul>
        <li><strong>可视化流程</strong>：所见即所得，方便调试与复用。</li>
        <li><strong>高度可扩展</strong>：支持自定义节点与各类插件。</li>
        <li><strong>精细控制</strong>：对采样、引导、VAE、LoRA、ControlNet 等细节可逐一调参。</li>
      </ul>

      <h2 id="install">2. 安装与启动</h2>
      <h3>2.1 环境准备</h3>
      <ul>
        <li>操作系统：Windows 10/11（推荐）、Linux、macOS</li>
        <li>Python：3.10 或 3.11</li>
        <li>Git：用于拉取仓库与更新</li>
        <li>GPU（推荐）：NVIDIA 显卡 + 合适的 CUDA 驱动</li>
      </ul>
      <h4>2.1.1 电脑配置推荐（保证良好体验）</h4>
      <div class="cards" style="margin-top:12px">
        <article class="card">
          <h3>入门可用（1080p 起步）</h3>
          <ul>
            <li>GPU：RTX 3060 12GB 或 RTX 4060 8GB</li>
            <li>CPU：6 核以上（Intel i5-12400/AMD 5600 及以上）</li>
            <li>内存：16GB</li>
            <li>硬盘：NVMe SSD ≥ 1TB（模型/缓存更快）</li>
            <li>适用：768～1024 分辨率，基础文生图/图生图</li>
          </ul>
        </article>
        <article class="card">
          <h3>甜点畅玩（更流畅）</h3>
          <ul>
            <li>GPU：RTX 4070 12GB 或 RTX 4070 Super</li>
            <li>CPU：8 核以上（Intel i7-12700/AMD 7700 及以上）</li>
            <li>内存：32GB</li>
            <li>硬盘：NVMe SSD 1–2TB</li>
            <li>适用：1024～1536 分辨率，ControlNet/LoRA 多组合</li>
          </ul>
        </article>
        <article class="card">
          <h3>高阶创作（大图/多模型）</h3>
          <ul>
            <li>GPU：RTX 4080(S) 16GB 或 RTX 4090 24GB</li>
            <li>CPU：高频 8–16 核（Intel i7/i9 13 代或 Ryzen 7/9 新款）</li>
            <li>内存：64GB（多任务/大型工作流更稳）</li>
            <li>硬盘：NVMe SSD 2TB+（建议独立“模型盘”）</li>
            <li>适用：2K 以上分辨率、放大精修、批量生成与视频插件</li>
          </ul>
        </article>
      </div>
      <p class="notice">显存是影响体验的关键：<strong>≥12GB</strong> 可较为从容地运行 1024 分辨率和常用 ControlNet；若显存吃紧，可降低分辨率/批量或改用放大流程。</p>
      <p class="notice">移动端建议优先选配带独显（如 4070/4080）的游戏本，并确保电源模式为性能优先；Apple Silicon 可通过 WebUI/Apple ML 方案体验基础功能（速度较慢）。</p>
      <h3>2.2 获取代码与依赖</h3>
      <pre class="code"><code>git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
python -m venv venv
venv\Scripts\activate   # Windows；Linux/macOS 使用: source venv/bin/activate
pip install --upgrade pip
# 按你的 CUDA 版本安装 PyTorch（以下示例为 CUDA 12.1）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt</code></pre>
      <p>若无独显或仅测试环境，可安装 CPU 版 PyTorch（速度较慢）：</p>
      <pre class="code"><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu</code></pre>

      <h3>2.3 启动服务</h3>
      <pre class="code"><code>python main.py --listen 0.0.0.0 --port 8188</code></pre>
      <p>浏览器访问 <code>http://127.0.0.1:8188/</code>（或你的服务器 IP）。</p>

      <h3 id="online">2.4 在线体验（中国境内）</h3>
      <div class="cards">
        <article class="card">
          <h3>方案 A：国内云 GPU（推荐）</h3>
          <ul>
            <li>平台：阿里云、腾讯云、华为云、火山引擎等，优先选择 ≥12–24GB 显存规格。</li>
            <li>系统：Ubuntu 22.04 + NVIDIA 驱动 + 匹配 CUDA。</li>
            <li>部署（示例）：</li>
          </ul>
          <pre class="code"><code>sudo apt update && sudo apt install -y git python3-venv
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
python3 -m venv venv && source venv/bin/activate
pip install --upgrade pip
# 按你的 CUDA 版本选择 PyTorch（示例 CUDA 12.1）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
python main.py --listen 0.0.0.0 --port 8188
# 在云厂商安全组/防火墙放行 80/443（反代）或 8188 端口</code></pre>
        </article>

        <article class="card">
          <h3>方案 B：Notebook / 容器平台</h3>
          <ul>
            <li>在支持 GPU 的国内平台创建 Notebook/容器实例。</li>
            <li>按上面命令拉取并运行，开启“端口映射/临时公网服务”。</li>
            <li>特点：计时计费、按需开关，适合教学演示与短期使用。</li>
          </ul>
        </article>

        <article class="card">
          <h3>方案 C：内网部署 + 远程访问</h3>
          <ul>
            <li>在办公室/家中独显主机上部署 ComfyUI。</li>
            <li>通过 FRP/ZeroTier/内网穿透或 Nginx 反向代理，以 HTTPS 暴露访问。</li>
            <li>务必启用访问控制与速率限制，保护模型与图片隐私。</li>
          </ul>
        </article>
      </div>
      <p class="notice">提示：公开在线服务需遵守版权与内容合规；为控制成本可设置“空闲自动关机/释放实例”；建议用域名 + HTTPS 代理至 8188 端口。</p>

      <h2 id="ui">3. 界面与节点基础</h2>
      <ul>
        <li><strong>画布（Canvas）</strong>：放置与连接节点的区域，支持拖拽与缩放。</li>
        <li><strong>节点搜索</strong>：双击画布或空格键，快速创建所需节点。</li>
        <li><strong>侧边栏</strong>：队列、历史记录、性能统计、系统日志等。</li>
        <li><strong>参数面板</strong>：选中节点后在右侧栏调参。</li>
      </ul>
      <p><strong>常用节点速览</strong>：</p>
      <ul>
        <li>模型相关：Load Checkpoint、VAE Encode/Decode、CLIP Text Encode</li>
        <li>采样相关：KSampler（选择采样器、步数、CFG 等）</li>
        <li>图像 I/O：Load Image、Save Image</li>
        <li>控制相关：Load ControlNet Model、Apply ControlNet</li>
      </ul>

      <h2 id="workflows">4. 核心工作流实战</h2>
      <h3>4.1 文生图（Text-to-Image）</h3>
      <ol>
        <li>添加 <em>Load Checkpoint</em>（选择主模型）</li>
        <li>添加 <em>CLIP Text Encode</em> 两个节点：Prompt 与 Negative Prompt</li>
        <li>添加 <em>Empty Latent Image</em>（设置分辨率，如 1024×1024）</li>
        <li>添加 <em>KSampler</em>（采样器、步数、CFG、种子）</li>
        <li>添加 <em>VAE Decode</em> 与 <em>Save Image</em></li>
      </ol>
      <p><strong>连接关系（简化）</strong>：</p>
      <pre class="code"><code>Load Checkpoint → KSampler（model、vae、clip）
CLIP Text Encode（正） → KSampler positive
CLIP Text Encode（负） → KSampler negative
Empty Latent Image → KSampler latent
KSampler → VAE Decode → Save Image</code></pre>

      <h3>4.2 图生图（Image-to-Image）</h3>
      <ol>
        <li><em>Load Image</em> → <em>VAE Encode</em> 获取 latent</li>
        <li>与 4.1 类似连接到 <em>KSampler</em>，但 latent 输入来自 <em>VAE Encode</em></li>
        <li>采样强度可通过步数、噪声、去噪强度等控制</li>
      </ol>

      <h3>4.3 ControlNet（结构/姿态/边缘约束）</h3>
      <ol>
        <li>添加 <em>Load ControlNet Model</em>（选择相应的 control 模型）</li>
        <li>添加预处理（如 Canny、OpenPose 等，部分需扩展节点）并输出提示图</li>
        <li><em>Apply ControlNet</em> 将控制条件接入 <em>KSampler</em></li>
      </ol>
      <p>建议从 Canny/Lineart 入手，权重从 0.8 降到 0.4 寻找平衡。</p>

      <h3>4.4 LoRA（风格/角色注入）</h3>
      <ol>
        <li>将 LoRA 模型放到 <code>models/loras</code></li>
        <li>使用 <em>CLIP Text Encode</em> 的提示词中添加 <code>&lt;lora:名称:权重&gt;</code></li>
        <li>或使用相应的 LoRA 注入节点（部分为扩展节点）</li>
      </ol>

      <h3>4.5 放大与精修（Upscale & Refine）</h3>
      <ul>
        <li>基础放大：<em>Upscale</em> 节点（选择算法：ESRGAN/BSRGAN/Nearest 等）</li>
        <li>高分修复：先放大后再进 <em>VAE Encode → KSampler → VAE Decode</em> 做细化</li>
        <li>面部修复：GFPGAN/CodeFormer（通常作为扩展节点）</li>
      </ul>

      <h2 id="models">5. 模型管理与放置路径</h2>
      <ul>
        <li>主模型（.safetensors/.ckpt）：<code>models/checkpoints</code></li>
        <li>VAE：<code>models/vae</code></li>
        <li>LoRA：<code>models/loras</code></li>
        <li>ControlNet：<code>models/controlnet</code></li>
        <li>嵌入/文本反演（Textual Inversion）：<code>embeddings</code></li>
      </ul>
      <p>放置完毕后在 UI 中点刷新（或重启）以识别新模型。</p>

      <h2 id="optimize">6. 性能优化建议</h2>
      <ul>
        <li>优先使用与显卡驱动匹配的 CUDA + PyTorch 版本</li>
        <li>分辨率从 768 或 1024 起步，逐步提升，结合放大流程</li>
        <li>采样步数常用 20–30，CFG 6–8 起步，按风格微调</li>
        <li>显存吃紧可降低 batch、分辨率，或启用 xformers/半精度</li>
        <li>固定随机种子以复现结果；探索时使用 -1 随机</li>
      </ul>

      <h2 id="export">7. 工作流的保存与分享</h2>
      <ul>
        <li>右上角导出/保存 <code>workflow.json</code></li>
        <li>他人可通过导入 JSON 快速复现你的流程</li>
        <li>截图画布并附上主要参数，有助于协作讨论</li>
      </ul>

      <h2 id="troubleshooting">8. 常见问题排查</h2>
      <details>
        <summary>8.1 启动后网页打不开</summary>
        <ul>
          <li>确认控制台无报错，端口 8188 未被占用</li>
          <li>尝试 <code>http://127.0.0.1:8188/</code> 或关闭代理软件</li>
          <li>服务器部署需放行防火墙端口或经反向代理暴露</li>
        </ul>
      </details>
      <details>
        <summary>8.2 无法识别 GPU / 加速无效</summary>
        <ul>
          <li>确认安装了 <strong>匹配 CUDA 版本</strong> 的 PyTorch（官网选择器）</li>
          <li>更新显卡驱动，检查 <code>nvidia-smi</code> 是否正常</li>
          <li>若仍失败，先用 CPU 版验证环境，再回退/更换 CUDA 版本</li>
        </ul>
      </details>
      <details>
        <summary>8.3 模型未显示或加载失败</summary>
        <ul>
          <li>确认放置在正确目录（见第 5 节）</li>
          <li>模型文件损坏可对比哈希或重新下载</li>
          <li>重启 ComfyUI 或点击 UI 刷新列表</li>
        </ul>
      </details>

      <h2 id="online-cn">9. 在线部署与体验（中国境内）</h2>
      <p class="lead">面向中国境内用户提供可落地的在线访问方案，包括国内云 GPU、Docker/Notebook 平台与内网部署穿透，以及安全加固与运维要点。</p>

      <h3>9.1 方案选择速览</h3>
      <div class="cards">
        <article class="card">
          <h3>国内云 GPU（推荐）</h3>
          <ul>
            <li>优点：弹性计费、带宽稳定、备案域名可用、维护省心</li>
            <li>建议：选择 ≥12–24GB 显存（如 L4/4090/A10/3090）</li>
            <li>适用：对外演示、团队协作、长期稳定服务</li>
          </ul>
        </article>
        <article class="card">
          <h3>Docker / Notebook 平台</h3>
          <ul>
            <li>优点：即开即用、镜像封装、便于教学与短期实验</li>
            <li>建议：开启端口映射或临时公网访问，挂载数据盘</li>
            <li>适用：课堂演示、临时项目、多人共享算力</li>
          </ul>
        </article>
        <article class="card">
          <h3>内网部署 + 穿透</h3>
          <ul>
            <li>优点：本地显卡零成本复用、可离线</li>
            <li>建议：使用 FRP/ZeroTier/反向代理并启用鉴权与限速</li>
            <li>适用：个人/小组内部访问，对公网稳定性要求不高</li>
          </ul>
        </article>
      </div>

      <h3>9.2 国内云 GPU 部署（生产推荐）</h3>
      <ol>
        <li><strong>创建实例</strong>：选择带 NVIDIA 显卡的镜像（或厂商提供的深度学习镜像）。显存 ≥12GB 为佳。</li>
        <li><strong>放行端口</strong>：安全组开放 22、80、443（用于反向代理与证书），可选开放 8188（直连）。</li>
        <li><strong>安装依赖并部署</strong>（Ubuntu 22.04 示例）：</li>
      </ol>
      <pre class="code"><code>sudo apt update && sudo apt install -y git python3-venv nginx apache2-utils
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
python3 -m venv venv && source venv/bin/activate
pip install --upgrade pip
# 按 CUDA 版本选择 PyTorch（示例 CUDA 12.1）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
nohup python main.py --listen 127.0.0.1 --port 8188 & disown
</code></pre>
      <p>说明：服务仅监听 127.0.0.1，由 Nginx 反代对外暴露，便于加密与鉴权。</p>

      <h4>为域名配置 Nginx 反向代理 + 基本认证</h4>
      <pre class="code"><code># 创建访问账户（可多次新增）
sudo htpasswd -c /etc/nginx/.htpasswd admin

sudo tee /etc/nginx/sites-available/comfyui &>/dev/null &lt;&lt;'CONF'
server {
  listen 80;
  server_name comfy.example.com;  # 改为你的域名

  location / {
    proxy_pass http://127.0.0.1:8188;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    auth_basic "Restricted";
    auth_basic_user_file /etc/nginx/.htpasswd;
    # 简单限速（可选）
    limit_req_zone $binary_remote_addr zone=one:10m rate=5r/s;
    limit_req zone=one burst=10 nodelay;
  }
}
CONF

sudo ln -s /etc/nginx/sites-available/comfyui /etc/nginx/sites-enabled/comfyui
sudo nginx -t && sudo systemctl reload nginx
</code></pre>
      <p class="notice">HTTPS：可用证书管理服务或 <code>acme.sh</code> 一键申请并将上面 server 块改为 443，强烈建议启用。</p>

      <h3>9.3 Docker / Notebook 快速方案</h3>
      <p>若平台提供 GPU Notebook/容器，可直接按下述命令启动（Ubuntu + NVIDIA Container Toolkit 示例）。</p>
      <pre class="code"><code># 安装 Docker 与 NVIDIA 容器支持
curl -fsSL https://get.docker.com | sudo sh
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt update && sudo apt install -y nvidia-container-toolkit && sudo systemctl restart docker

# 以 CUDA 运行时镜像启动容器并内部部署 ComfyUI（简化示例）
docker run --gpus all -d --name comfyui -p 8188:8188 \
  -v /data/comfyui:/workspace \
  nvidia/cuda:12.1.1-cudnn-runtime-ubuntu22.04 bash -lc '
    apt update && apt install -y git python3-venv && \
    cd /workspace && git clone https://github.com/comfyanonymous/ComfyUI.git && \
    cd ComfyUI && python3 -m venv venv && . venv/bin/activate && \
    pip install --upgrade pip && \
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 && \
    pip install -r requirements.txt && \
    python main.py --listen 0.0.0.0 --port 8188'
</code></pre>
      <p class="notice">如平台自带“临时公网/端口映射”，将 8188 映射出去即可；或同 9.2 用 Nginx 做 80/443 反代与鉴权。</p>

      <h3>9.4 内网部署 + 穿透（FRP 示例）</h3>
      <p>准备一台具有公网 IP 的轻量服务器部署 frps，本地显卡主机运行 frpc，将内网 8188 暴露为域名访问。</p>
      <pre class="code"><code># 在公网服务器安装 frps（以二进制包为例）
wget https://github.com/fatedier/frp/releases/download/v0.58.0/frp_0.58.0_linux_amd64.tar.gz
tar xf frp_0.58.0_linux_amd64.tar.gz && cd frp_0.58.0_linux_amd64
cat &gt; frps.ini &lt;&lt;EOF
[common]
bind_port = 7000
vhost_http_port = 80
vhost_https_port = 443
EOF
./frps -c frps.ini

# 本地显卡主机（Windows/Linux）创建 frpc.ini
[common]
server_addr = 公网服务器IP
server_port = 7000
[comfyui]
type = http
local_port = 8188
custom_domains = comfy.yourdomain.com

# 启动 frpc 后，用域名访问；可再配 Nginx/HTTPS 与基本认证
</code></pre>

      <h3>9.5 作为系统服务运行（systemd）</h3>
      <pre class="code"><code>sudo tee /etc/systemd/system/comfyui.service &>/dev/null &lt;&lt;'UNIT'
[Unit]
Description=ComfyUI Service
After=network.target

[Service]
WorkingDirectory=/opt/ComfyUI
ExecStart=/opt/ComfyUI/venv/bin/python main.py --listen 127.0.0.1 --port 8188
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
UNIT
sudo systemctl daemon-reload
sudo systemctl enable --now comfyui
</code></pre>

      <h3>9.6 安全与运维清单</h3>
      <ul>
        <li>避免直连 8188，对外统一走 Nginx 443，启用 HTTPS 与基本认证。</li>
        <li>限制上传与并发、开启限速；必要时加 WAF/防火墙白名单。</li>
        <li>模型与生成内容合规：注意版权、人物肖像与敏感内容过滤。</li>
        <li>成本控制：空闲自动关机/释放实例，定时同步模型至对象存储。</li>
        <li>监控：<code>nvidia-smi -l</code> 观察显存/功耗，日志保存在运行目录。</li>
      </ul>

      <h3 id="runninghub">9.7 基于 RunningHub 的云平台学习教程</h3>
      <p>以下步骤基于 <a href="https://www.runninghub.cn/" target="_blank" rel="noopener">RunningHub</a> 云端 ComfyUI 平台整理，适合希望“开箱即用、按使用时长计费”的同学。平台提供“工作流编辑/运行、模型库、节点每日更新、AI 应用发布与 API 调用”等能力。</p>

      <h4>一、注册与进入工作台</h4>
      <ol>
        <li>访问 <a href="https://www.runninghub.cn/" target="_blank" rel="noopener">RunningHub</a>，完成注册并登录；点击“工作台”进入个人工作空间。</li>
        <li>可先浏览“工作流/作品广场”，将喜欢的示例一键“复制到我的工作台”。</li>
        <li>如需从零开始，选择“快捷创作/新建工作流”，创建空白 ComfyUI 画布。</li>
      </ol>

      <h4>二、获取或导入工作流</h4>
      <ul>
        <li><strong>导入 JSON：</strong>在工作台中选择“导入工作流”，上传本地 <code>workflow.json</code>；或将他人分享的 JSON 粘贴导入。</li>
        <li><strong>从广场复制：</strong>在“工作流/作品广场”找到合适的模板，一键复制到工作台后打开编辑。</li>
        <li><strong>模型准备：</strong>平台内置丰富模型库（如 Stable Diffusion、Flux、CogVideo 等），在节点或模型面板中直接选择即可；无需手动上传驱动和依赖。</li>
      </ul>

      <h4>三、编辑与运行</h4>
      <ol>
        <li>在画布双击或通过搜索创建节点（如 Load Checkpoint、CLIP Text Encode、KSampler、VAE Decode、Save Image）。</li>
        <li>根据教程第 4 节的连接关系完成链路；节点参数修改后可保存版本。</li>
        <li>点击“运行/提交”，在右侧或底部查看任务队列与日志输出；运行按 GPU 使用时间计费，结束会话以节省费用。</li>
        <li>输出图片可在结果面板预览与下载；支持将关键中间图（如 Canny 结果）保存为附件。</li>
      </ol>

      <h4>四、发布为在线应用</h4>
      <ol>
        <li>在工作台选中工作流，点击“发布应用”。</li>
        <li>为输入项（Prompt、Steps、CFG、分辨率、上传图像等）配置表单组件，映射到画布对应节点参数。</li>
        <li>设置输出展示（图片/链接/JSON）；选择计费与可见范围（私有/公开）。</li>
        <li>发布完成后获得可分享的应用 URL，可用于演示或内外部使用。</li>
      </ol>

      <h4>五、通过 API 调用工作流</h4>
      <ol>
        <li>进入“API 调用”，获取个人 <em>Access Token</em> 与目标工作流的 <em>Workflow ID</em> 或“调用地址”。</li>
        <li>根据页面提供的示例（平台会生成对应 cURL/SDK 样例）进行调用；一般请求体包含输入参数，响应返回任务 ID。</li>
        <li>使用“查询任务/多任务状态”接口轮询任务进度，完成后拉取结果 URL 或二进制内容。</li>
      </ol>
      <pre class="code"><code># 通用示例（以平台页面的实际调用地址与字段为准）
curl -X POST "&lt;调用地址&gt;" \
  -H "Authorization: Bearer &lt;ACCESS_TOKEN&gt;" \
  -H "Content-Type: application/json" \
  -d '{
    "workflowId": "&lt;WORKFLOW_ID&gt;",
    "inputs": {
      "prompt": "a cat in the garden, 4k",
      "negative": "lowres, bad anatomy",
      "steps": 25,
      "cfg": 7,
      "width": 1024,
      "height": 1024
    }
  }'

# 轮询任务（平台会提供查询地址与任务ID字段）
curl -H "Authorization: Bearer &lt;ACCESS_TOKEN&gt;" "&lt;查询地址&gt;?taskId=&lt;TASK_ID&gt;"
</code></pre>

      <h4>六、费用与配额</h4>
      <ul>
        <li>按运行时长与所选 GPU 规格计费；通过工作台“账单/用量”查看明细。</li>
        <li>长时间空闲请关闭运行会话或释放实例；批量任务建议分时段提交以控制成本。</li>
      </ul>

      <h4>七、团队协作与社区</h4>
      <ul>
        <li>将工作流“私有/共享/公开”灵活设置，便于团队内协作或与社区交流。</li>
        <li>利用“工作流/模型库/AI 应用”模块学习他人最佳实践并复用。</li>
      </ul>

      <h4>八、常见问题</h4>
      <ul>
        <li><strong>节点报红：</strong>平台提供海量预装节点，通常直接可用；若仍报红，多为参数不兼容或引用了未启用的扩展，复制广场同款示例可快速对照修复。</li>
        <li><strong>显存不足：</strong>降低分辨率/批量或尝试放大流程；选用更高显存规格可显著改善。</li>
        <li><strong>访问慢/失败：</strong>优先使用平台给出的应用/API 域名，避开直连内网；留意高峰期排队与并发限制。</li>
      </ul>

      <p class="notice">更多能力（工作流广场、模型库、API 与计费等）可参考平台页面与文档：<a href="https://www.runninghub.cn/" target="_blank" rel="noopener">RunningHub 官网</a>。</p>

      <h3 id="liblib">9.8 基于 Liblib.art 的云平台学习教程</h3>
      <p>以下步骤基于 <a href="https://www.liblib.art/" target="_blank" rel="noopener">Liblib.art</a> 整理，目标是无需本地显卡即可在线编辑与运行 ComfyUI 工作流，并可分享/对外提供结果。</p>

      <h4>一、注册与进入工作区</h4>
      <ol>
        <li>访问 <a href="https://www.liblib.art/" target="_blank" rel="noopener">Liblib.art</a>，完成注册与登录。</li>
        <li>从首页导航进入与 ComfyUI 相关的功能入口（如“工作流/工作台/AI 应用”等，以网站当前导航为准）。</li>
        <li>初学者可先浏览平台示例与社区作品，了解常用节点与工作流结构。</li>
      </ol>

      <h4>二、创建或导入工作流</h4>
      <ul>
        <li><strong>新建：</strong>在工作区新建 ComfyUI 工作流，进入画布编辑。</li>
        <li><strong>导入：</strong>选择“导入工作流”，上传本地 <code>workflow.json</code> 或粘贴 JSON 内容。</li>
        <li><strong>复制示例：</strong>在社区/作品广场中挑选模板，一键复制到个人空间后打开编辑。</li>
      </ul>

      <h4>三、模型与节点</h4>
      <ul>
        <li><strong>模型库：</strong>平台内置常用模型与 LoRA，直接在节点/模型面板选择；通常无需自行安装驱动与 CUDA。</li>
        <li><strong>自有模型：</strong>按平台指引上传到个人空间，并在工作流节点中选择对应路径或名称。</li>
        <li><strong>节点更新：</strong>若节点报红，优先检查是否使用了未启用的扩展或不兼容版本；复制平台同款示例对照参数可快速排查。</li>
      </ul>

      <h4>四、编辑与运行</h4>
      <ol>
        <li>按教程第 4 节的链路（Load Checkpoint → KSampler → VAE Decode → Save Image 等）搭建或检查连线。</li>
        <li>设置 Prompt/Negative、Steps、CFG、分辨率与采样器；需要时加入 ControlNet/LoRA 节点。</li>
        <li>点击“运行/提交”，在队列/日志面板查看状态；运行按平台计费规则计费，结束会话可节省成本。</li>
        <li>完成后在结果面板预览与下载图片，必要时保存中间结果便于复现。</li>
      </ol>

      <h4>五、发布与分享</h4>
      <ol>
        <li>选择工作流，点击“发布/分享”。</li>
        <li>为常用输入（Prompt、步数、CFG、分辨率、上传图像等）配置表单并映射到节点参数。</li>
        <li>设置可见性（私有/公开/团队）与配额限制，生成分享链接用于演示或收集反馈。</li>
      </ol>

      <h4>六、API 与自动化（如平台开放）</h4>
      <p>若平台提供 API 调用，一般包括：获取 Token/工作流 ID → 触发运行 → 轮询任务 → 获取结果。以下为通用模板，字段以平台文档为准。</p>
      <pre class="code"><code>curl -X POST "&lt;API_调用地址&gt;" \
  -H "Authorization: Bearer &lt;ACCESS_TOKEN&gt;" \
  -H "Content-Type: application/json" \
  -d '{"workflowId":"&lt;WORKFLOW_ID&gt;","inputs":{"prompt":"sunset city","steps":20,"cfg":7}}'

curl -H "Authorization: Bearer &lt;ACCESS_TOKEN&gt;" "&lt;API_查询地址&gt;?taskId=&lt;TASK_ID&gt;"
</code></pre>

      <h4>七、费用与配额</h4>
      <ul>
        <li>根据算力规格与使用时长计费；在账户/账单处查看用量明细。</li>
        <li>请在空闲时及时结束会话或释放实例，避免空转。</li>
      </ul>

      <h4>八、常见问题</h4>
      <ul>
        <li><strong>节点报红：</strong>检查模型是否存在/可用、节点版本是否匹配；用社区同款示例对比参数更易定位问题。</li>
        <li><strong>显存不足：</strong>降低分辨率/批量或采用放大流程；必要时切换到更高显存算力。</li>
        <li><strong>访问慢/失败：</strong>避开高峰期、分批运行；关注平台的并发/排队机制。</li>
      </ul>

      <p class="notice">平台入口：<a href="https://www.liblib.art/" target="_blank" rel="noopener">Liblib.art</a>（请以站内导航与文档为准）。</p>

      <h3 id="liblib-lora">9.9 Liblib.art 上训练 LoRA（详细教程）</h3>
      <p>以下流程面向“风格/角色/产品”三类常见 LoRA 训练场景，参数区分给出推荐值；请结合平台的“模型训练”界面逐项对应设置。</p>

      <h4>一、前置准备</h4>
      <ul>
        <li>账号与配额：保证有可用算力与存储额度；训练时长按规格计费。</li>
        <li>数据集：
          <ul>
            <li>风格 LoRA：50–200 张，多题材多视角；角色/产品 LoRA：200–800 张，覆盖正脸/侧脸/半身/全身与不同光线。</li>
            <li>分辨率建议：长边 768–1024，尽量无水印与文字；可先做去噪/裁切。</li>
            <li>命名与标签：准备唯一触发词（如 <code>sksChar</code>），用于提示词中触发 LoRA。</li>
          </ul>
        </li>
        <li>标注方式：使用平台的自动标注工具（如 WD14/BLIP 等）为图片生成 caption；必要图片手工微调关键词。</li>
      </ul>

      <h4>二、创建训练任务</h4>
      <ol>
        <li>进入 <em>模型训练</em> → 新建 <em>LoRA 训练</em>（名称、描述、触发词）。</li>
        <li>选择基底模型系列（SD 1.5 / SDXL / Flux 等），与后续推理要用的底模保持一致。</li>
        <li>选择数据集来源：上传图片与 caption，或选择已整理好的数据集目录。</li>
      </ol>

      <h4>三、关键参数推荐</h4>
      <div class="cards">
        <article class="card">
          <h3>风格 LoRA（轻量）</h3>
          <ul>
            <li>Rank / Alpha：<strong>8–16 / 8–16</strong></li>
            <li>分辨率：<strong>768</strong>（SDXL 可 1024）</li>
            <li>学习率：UNet <strong>1e-4</strong>，Text Encoder <strong>1e-5</strong></li>
            <li>批量：BS 2–4；梯度累积到等效 <strong>16</strong></li>
            <li>步数：<strong>2k–4k</strong>；保存间隔 500</li>
            <li>调度器：cosine，warmup 0.05；精度：fp16/bf16</li>
          </ul>
        </article>
        <article class="card">
          <h3>角色 LoRA（中等）</h3>
          <ul>
            <li>Rank / Alpha：<strong>16–32 / 8–16</strong></li>
            <li>分辨率：<strong>768</strong>（SDXL 1024）</li>
            <li>学习率：UNet <strong>1e-4</strong>，Text Encoder <strong>5e-6–1e-5</strong></li>
            <li>批量：BS 2–4；梯度累积到等效 16–32</li>
            <li>步数：<strong>3k–8k</strong>；保存间隔 500</li>
            <li>建议先训 70% 仅 UNet，后 30% 打开 Text Encoder 微调</li>
          </ul>
        </article>
        <article class="card">
          <h3>产品/IP LoRA（细节多）</h3>
          <ul>
            <li>Rank / Alpha：<strong>32–64 / 16–32</strong></li>
            <li>分辨率：<strong>896–1024</strong></li>
            <li>学习率：UNet <strong>5e-5–1e-4</strong>，Text Encoder <strong>5e-6</strong></li>
            <li>批量：等效 16–32；开启 gradient checkpoint 节省显存</li>
            <li>步数：<strong>5k–12k</strong>，根据过拟合迹象提前停止</li>
          </ul>
        </article>
      </div>
      <p class="notice">计算步数参考：<code>有效批量 × 训练步数 ≈ 数据量 × repeats × epoch</code>；优先以“验证效果”而非固定步数为准。</p>

      <h4>四、训练与监控</h4>
      <ul>
        <li>启动后关注 loss 曲线、显存占用与日志；过拟合常表现为训练后期图像发糊、细节异常统一。</li>
        <li>中断可从最近保存步继续；建议每 500–1000 步导出一次以便对比。</li>
      </ul>

      <h4>五、验证与发布</h4>
      <ol>
        <li>训练完成后，在平台“模型库/我的模型”中找到 LoRA；用于推理时直接在 ComfyUI 节点中选择。</li>
        <li>在 ComfyUI 中的使用：
          <ul>
            <li>提示词触发：<code>&lt;lora:你的LoRA名称:0.6–1.0&gt;</code>（或使用 LoRA 注入节点）。</li>
            <li>权重经验值：风格 0.6–0.8；角色 0.8–1.2；产品 0.7–1.0。</li>
          </ul>
        </li>
        <li>对比不同保存步的效果，选择最佳权重作为“发布版”。</li>
      </ol>

      <h4>六、常见问题与排错</h4>
      <ul>
        <li><strong>不收敛/风格不明显：</strong>增加数据多样性与数量，适当提高 rank 或步数。</li>
        <li><strong>过拟合（统一脸/纹理）：</strong>降低步数或学习率，加入负面标签，扩大数据多样性。</li>
        <li><strong>显存不足：</strong>降低分辨率/批量，启用梯度检查点，或选择更高显存规格。</li>
        <li><strong>结果偏离主题：</strong>固定触发词并在 caption 中前置；清理无关/含文字图片。</li>
      </ul>

      <p class="notice">更多入口与说明见：<a href="https://www.liblib.art/" target="_blank" rel="noopener">Liblib.art</a>；请以平台训练界面字段为准逐项对应。</p>
    </article>
  </main>

  <footer class="site-footer">
    <div class="container">
      <span>© 2025 ComfyUI 学习站</span>
      <span class="sep">·</span>
      <a href="./index.html">首页</a>
      <span class="sep">·</span>
      <a href="./cases.html">案例展示</a>
    </div>
  </footer>

  <script src="./main.js"></script>
</body>
</html>


